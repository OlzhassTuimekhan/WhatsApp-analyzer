"""–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Ç–∞"""
import json
from typing import List, Dict, Any, Optional
from openai import OpenAI


class ChatAnalyzerAI:
    """AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —á–∞—Ç–∞ —á–µ—Ä–µ–∑ OpenAI"""
    
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
        self.model = "gpt-4o-mini"
    
    def ask_question(
        self, 
        question: str, 
        analysis: Dict, 
        messages_sample: List[Dict] = None,
        conversation_history: List[Dict] = None,
        day_analysis: Dict = None
    ) -> str:
        """
        –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å AI –æ —á–∞—Ç–µ
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            analysis: –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–∞—Ç–∞ (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
            messages_sample: –ü—Ä–∏–º–µ—Ä—ã —Å–æ–æ–±—â–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N)
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ —Å AI
        """
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = """–¢—ã —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–µ–ø–∏—Å–∫–∏ WhatsApp. 
–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø–æ–Ω—è—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –µ–≥–æ —á–∞—Ç–∞.

–£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫:
1. –ü–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ —á–∞—Ç–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–ª–æ–≤–∞, —ç–º–æ–¥–∑–∏, –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ —Ç.–¥.)
2. –ü—Ä–∏–º–µ—Ä–∞–º —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ø–µ—Ä–µ–ø–∏—Å–∫–∏
3. –ê–Ω–∞–ª–∏–∑—É –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏, —É—á–∞—Å—Ç–Ω–∏–∫–∞–º –∏ —Ç.–¥.

–û—Ç–≤–µ—á–∞–π:
- –ö—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É
- –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
- –ù–∞—Ö–æ–¥–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏
- –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º
- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º
        analysis_summary = self._format_analysis(analysis)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–Ω—è, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        day_context = ""
        if day_analysis and 'error' not in day_analysis:
            day_context = "\n\nüìÖ –ê–ù–ê–õ–ò–ó –ö–û–ù–ö–†–ï–¢–ù–û–ì–û –î–ù–Ø:\n"
            day_context += f"–î–∞—Ç–∞: {day_analysis.get('date', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
            
            if 'basic' in day_analysis:
                basic = day_analysis['basic']
                day_context += f"- –°–æ–æ–±—â–µ–Ω–∏–π –∑–∞ –¥–µ–Ω—å: {basic.get('total_messages', 0)}\n"
                day_context += f"- –°–ª–æ–≤: {basic.get('total_words', 0)}\n"
                day_context += f"- –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è: {basic.get('avg_message_length', 0):.0f} —Å–∏–º–≤–æ–ª–æ–≤\n"
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º –∏–∑ basic
            if 'basic' in day_analysis and 'author_stats' in day_analysis['basic']:
                day_context += "\n–ü–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º:\n"
                for author, count in day_analysis['basic']['author_stats'].items():
                    day_context += f"- {author}: {count} —Å–æ–æ–±—â–µ–Ω–∏–π\n"
            
            if 'activity' in day_analysis and 'hourly' in day_analysis['activity']:
                hourly = day_analysis['activity']['hourly']
                if hourly:
                    max_hour = max(hourly, key=lambda x: x[1])
                    day_context += f"\n–°–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Å: {max_hour[0]}:00 ({max_hour[1]} —Å–æ–æ–±—â–µ–Ω–∏–π)\n"
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø —Å–ª–æ–≤ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã words
            if 'words' in day_analysis and 'top_words' in day_analysis['words']:
                words = day_analysis['words']['top_words'][:5]
                if words:
                    day_context += f"\n–¢–æ–ø-5 —Å–ª–æ–≤: {', '.join([f'{w[0]} ({w[1]})' for w in words])}\n"
            
            day_context += "\n–í–ê–ñ–ù–û: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –æ –ö–û–ù–ö–†–ï–¢–ù–û–ú –î–ù–ï. –û—Ç–≤–µ—á–∞–π —Å —É—á–µ—Ç–æ–º –∞–Ω–∞–ª–∏–∑–∞ —ç—Ç–æ–≥–æ –¥–Ω—è!"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å–æ–æ–±—â–µ–Ω–∏–π
        messages_context = ""
        if messages_sample:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 30 –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            sample_size = min(30, len(messages_sample))
            first_messages = messages_sample[:sample_size]
            last_messages = messages_sample[-sample_size:] if len(messages_sample) > sample_size else []
            
            messages_context = "\n\n–ü—Ä–∏–º–µ—Ä—ã —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –ø–µ—Ä–µ–ø–∏—Å–∫–∏ (–¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç–∏–ª—è –æ–±—â–µ–Ω–∏—è):\n"
            messages_context += "–ü–µ—Ä–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n"
            for msg in first_messages[:15]:  # –ü–µ—Ä–≤—ã–µ 15
                text = msg.get('text', '')[:150]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                messages_context += f"- [{msg.get('date', '')} {msg.get('time', '')}] {msg.get('author', '')}: {text}\n"
            
            if last_messages:
                messages_context += "\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n"
                for msg in last_messages[-15:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 15
                    text = msg.get('text', '')[:150]
                    messages_context += f"- [{msg.get('date', '')} {msg.get('time', '')}] {msg.get('author', '')}: {text}\n"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        if conversation_history and len(conversation_history) > 0:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë
            for msg in conversation_history:
                messages.append(msg)
        else:
            # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            context_parts = [f"–í–æ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ —á–∞—Ç–∞:\n\n{analysis_summary}"]
            
            if day_context:
                context_parts.append(day_context)
            
            if messages_context:
                context_parts.append(messages_context)
            
            context_parts.append("\n–¢–µ–ø–µ—Ä—å –æ—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ –µ–≥–æ –ø–µ—Ä–µ–ø–∏—Å–∫–µ.")
            
            context_message = "\n".join(context_parts)
            messages.append({"role": "user", "content": context_message})
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å
        messages.append({"role": "user", "content": question})
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=1500
            )
            
            return response.choices[0].message.content.strip()
        except Exception as e:
            raise ValueError(f"–û—à–∏–±–∫–∞ OpenAI API: {str(e)}")
    
    def _format_analysis(self, analysis: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ AI"""
        if not analysis or 'error' in analysis:
            return "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        
        summary = "–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ß–ê–¢–ê:\n\n"
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if 'basic' in analysis:
            basic = analysis['basic']
            summary += f"üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
            summary += f"- –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {basic.get('total_messages', 0):,}\n"
            summary += f"- –í—Å–µ–≥–æ —Å–ª–æ–≤: {basic.get('total_words', 0):,}\n"
            summary += f"- –î–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {basic.get('days_active', 0)}\n"
            summary += f"- –°–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–µ–Ω—å: {basic.get('messages_per_day', 0):.1f}\n"
            summary += f"- –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è: {basic.get('avg_message_length', 0):.0f} —Å–∏–º–≤–æ–ª–æ–≤\n\n"
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º
            if 'author_stats' in basic:
                summary += "üë• –ü–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º:\n"
                for author, count in basic['author_stats'].items():
                    percentage = (count / basic['total_messages'] * 100) if basic['total_messages'] > 0 else 0
                    summary += f"- {author}: {count:,} —Å–æ–æ–±—â–µ–Ω–∏–π ({percentage:.1f}%)\n"
                summary += "\n"
        
        # –≠–º–æ–¥–∑–∏
        if 'emoji' in analysis:
            emoji = analysis['emoji']
            summary += f"üòä –≠–º–æ–¥–∑–∏:\n"
            summary += f"- –í—Å–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π: {emoji.get('total_emojis', 0):,}\n"
            summary += f"- –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–º–æ–¥–∑–∏: {emoji.get('unique_emojis', 0)}\n"
            summary += f"- –°–æ–æ–±—â–µ–Ω–∏–π —Å —ç–º–æ–¥–∑–∏: {emoji.get('messages_with_emoji', 0):,} ({emoji.get('emoji_usage_percentage', 0):.1f}%)\n"
            if 'top_emojis' in emoji and emoji['top_emojis']:
                summary += f"- –¢–æ–ø-5 —ç–º–æ–¥–∑–∏: {', '.join([f'{e[0]} ({e[1]})' for e in emoji['top_emojis'][:5]])}\n"
            summary += "\n"
        
        # –¢–æ–ø —Å–ª–æ–≤
        if 'words' in analysis and 'top_words' in analysis['words']:
            words = analysis['words']['top_words'][:10]
            if words:
                summary += f"üìù –¢–æ–ø-10 —Å–ª–æ–≤: {', '.join([f'{w[0]} ({w[1]})' for w in words])}\n\n"
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        if 'activity' in analysis:
            activity = analysis['activity']
            if 'hourly' in activity:
                # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Å
                hourly = activity['hourly']
                max_hour = max(hourly, key=lambda x: x[1])
                summary += f"‚è∞ –°–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Å: {max_hour[0]}:00 ({max_hour[1]} —Å–æ–æ–±—â–µ–Ω–∏–π)\n"
            
            if 'weekday' in activity:
                weekday = activity['weekday']
                max_day = max(weekday, key=lambda x: x[1])
                summary += f"üìÖ –°–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏: {max_day[0]} ({max_day[1]} —Å–æ–æ–±—â–µ–Ω–∏–π)\n"
            summary += "\n"
        
        # –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Ñ–∞–∫—Ç—ã
        if 'interesting' in analysis:
            interesting = analysis['interesting']
            if 'top_active_days' in interesting and interesting['top_active_days']:
                top_day = interesting['top_active_days'][0]
                summary += f"üî• –°–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π –¥–µ–Ω—å: {top_day['date']} ({top_day['messages']} —Å–æ–æ–±—â–µ–Ω–∏–π)\n"
            if 'avg_response_time_minutes' in interesting:
                summary += f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {interesting['avg_response_time_minutes']:.1f} –º–∏–Ω—É—Ç\n"
            summary += "\n"
        
        return summary

